{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3ffb80c5-6778-4130-961b-aa17b57c7741",
    "_uuid": "8353a531a6034b1c21239bcf9657a94a718bcece",
    "id": "0bd44e88-5b96-47a7-9b33-594fe3eda60a"
   },
   "source": [
    "## Importing Necessary Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_active": false,
    "_cell_guid": "2d75481f-2b19-d824-6a77-a6f8fa1f63f8",
    "_execution_state": "idle",
    "_uuid": "e8e286a4d699f3294f0ff773baba59f015ae11b9",
    "id": "2da6fd89-0fd3-4748-b991-1301c891111a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt #for plotting\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f9f804d7-72e7-415f-88b9-f43ded389d39",
    "_uuid": "4375276c8b31c78a81859766e49db726e73cf4b5",
    "id": "11cfe16a-6454-49bd-a808-5c0fdca49b19"
   },
   "source": [
    "## Loading The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_active": true,
    "_cell_guid": "d2ecfe40-ec05-6623-6f2d-a296d7eeec9e",
    "_execution_state": "idle",
    "_uuid": "1de17f87d4eb39ebb9772e29bbc70186d09ac927",
    "id": "0a443905-7fab-4dad-bd8f-039d3f6de37d"
   },
   "outputs": [],
   "source": [
    "#loading the dataset.......(Train)\n",
    "train = pd.read_csv(os.environ['DSX_PROJECT_DIR']+'/datasets/train_digits.csv')\n",
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "58ab02cd56294ed99a2304f2bc30a102"
   },
   "outputs": [],
   "source": [
    "# get random sample data for scoring\n",
    "test_run_df = train.sample(frac=0.01, random_state=200)\n",
    "print(test_run_df.shape)\n",
    "test_run_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c0a0d235bc01467f89cc5461fed3f42f"
   },
   "outputs": [],
   "source": [
    "test_run_df.to_csv(os.environ['DSX_PROJECT_DIR']+'/datasets/test_df_digits_labeled.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6dfd458651e04010a40f8124724e580a"
   },
   "outputs": [],
   "source": [
    "test_run_df.drop('label', axis=1).to_csv(os.environ['DSX_PROJECT_DIR']+'/datasets/test_df_digits_unlabeled.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a190fd1e8db84a54afa8463b0d5d90dd"
   },
   "outputs": [],
   "source": [
    "train = train.drop(test_run_df.index)\n",
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "74d1193c-49c0-4f83-bb76-9280bf544959",
    "_uuid": "8da998a4c8f1e8ee218a6118217516754fb51868",
    "id": "312bd7a3-0b7c-427e-b069-38ea802fc1ee"
   },
   "outputs": [],
   "source": [
    "z_train = Counter(train['label'])\n",
    "z_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "49685d71-7f60-4df4-936e-1903e0d8bc97",
    "_uuid": "94787bc95e72b77062f3c997bab575584f10f5bf",
    "id": "1438e6ba-fe80-435b-b35b-377a5dd3aa7c"
   },
   "outputs": [],
   "source": [
    "sns.countplot(train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_active": false,
    "_cell_guid": "32eef273-6dd8-7bac-df10-691c90a4112f",
    "_execution_state": "idle",
    "_uuid": "3d5c172812a24ca6a65f6b57258a743d7e9da810",
    "id": "c415b35a-4a1e-404a-81d4-ac4680e6db4a"
   },
   "outputs": [],
   "source": [
    "#loading the dataset.......(Test)\n",
    "test= pd.read_csv(os.environ['DSX_PROJECT_DIR']+'/datasets/test_digits.csv')\n",
    "print(test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "04b01849-64c8-4701-9d1a-4622f827b1a2",
    "_execution_state": "idle",
    "_uuid": "9d47ae3027e049f31a0a3046da9db13c72c82e60",
    "id": "e655f029-7e78-4a66-a53b-94fd9742255e"
   },
   "outputs": [],
   "source": [
    "x_train = (train.iloc[:,1:].values).astype('float32') # all pixel values\n",
    "y_train = train.iloc[:,0].values.astype('int32') # only labels i.e targets digits\n",
    "x_test = test.values.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fe3486b1-1e6b-472a-9512-dc893cbdb166",
    "_uuid": "46f3eed5b689e4d69dd9ebaa67665fbcaeadb4fc",
    "id": "90812bb4-4b8b-4663-8d03-3810d0d41e72"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# preview the images first\n",
    "plt.figure(figsize=(12,10))\n",
    "x, y = 10, 4\n",
    "for i in range(40):  \n",
    "    plt.subplot(y, x, i+1)\n",
    "    plt.imshow(x_train[i].reshape((28,28)),interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ad1ce800-483d-4d53-8e72-aac58e025625",
    "_uuid": "a57bba5834baddf55952760b01ccb7c492f7c7f7",
    "id": "efba0a50-5209-4503-a8f3-dbca7747b383"
   },
   "source": [
    "## Normalising The Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2af344a9-8fbe-4b2f-af5e-a108adf04722",
    "_execution_state": "idle",
    "_uuid": "29756ff1b015740f63a1e3b0ee707d4ee3ee0aab",
    "id": "f085010e-57fc-42f6-a996-44e8b067eb9a"
   },
   "outputs": [],
   "source": [
    "x_train = x_train/255.0\n",
    "x_test = x_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "632d3bf7-9682-4d6d-b51f-b1503190e2b6",
    "_execution_state": "idle",
    "_uuid": "e9e6b0fb776f4400788325fe66ac58f90f56388a",
    "id": "c474ec18-422d-47b8-935e-e031d68c1fd3"
   },
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "df775f7c-a839-4a9b-baee-bef876debd08",
    "_uuid": "98a75d9fb3e0ed369ccd0b4bb3f67805a51c8d95",
    "id": "6478ca65-82bf-46de-a8c8-70ca5a00295b"
   },
   "source": [
    "## Printing the shape of the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "72e903bd-ad8d-4751-ba2d-0deddadd4ab3",
    "_execution_state": "idle",
    "_uuid": "ac95a6317ce1baebb4f17d18388028318f48b509",
    "id": "bf65404c-b6d6-4a91-96f7-a075b814e235"
   },
   "outputs": [],
   "source": [
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e4e58453-9f36-4265-bdc7-0a3b5337129c",
    "_uuid": "478435d2e2526e99f684a8c063b05ae08a82e8f0",
    "id": "0b066986-7cdd-4acc-aa05-e2c14562b566"
   },
   "source": [
    ">  ## Reshape To Match The Keras's Expectations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5d6167d5-1e96-40e6-af0c-b960567ef033",
    "_execution_state": "idle",
    "_uuid": "5e4de6b35dbd4db773e890c4d16840485a4f74ad",
    "id": "5a47ef52-945f-465e-9b6a-172e76def930"
   },
   "outputs": [],
   "source": [
    "X_train = x_train.reshape(x_train.shape[0], 28, 28,1)\n",
    "X_test = x_test.reshape(x_test.shape[0], 28, 28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "bb79bc10-9ba2-44fe-a349-570520cd8a80",
    "_execution_state": "idle",
    "_uuid": "297c1b8aab418daee490ae79f474ca7814d86378",
    "id": "c575e088-1998-4040-b6fb-a6d86d1396ea"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "epochs = 2\n",
    "input_shape = (28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8c4ecbcb-268c-48e3-ab93-9015e12d0e79",
    "_execution_state": "idle",
    "_uuid": "7a5463286287b10f7bdbbbfae8fabf764f6d5b1d",
    "id": "0d0dc705-902f-463d-bfff-a71a14b98a5c"
   },
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices One Hot Encoding\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b3446c4e1d2847788a98dc56c15a69c9"
   },
   "source": [
    "**Split data train and test sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d5d04b86d8714d949fbcb7d2ceaf0c3d"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, y_train, test_size = 0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4448455e-bbb5-4276-9d71-142d6b724c87",
    "_uuid": "56980ded182bdfd2eeb5b1fe919fdefe5cd5e309",
    "collapsed": true,
    "id": "e105ae90-d5a0-4267-b42d-46ddc5ede759"
   },
   "source": [
    "**Linear Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "097867df-c77b-4ca8-988a-7baea6f4e387",
    "_execution_state": "idle",
    "_uuid": "577c7efb2d90f284383906e712a68df6233fe4e0",
    "id": "8b64e271-8ff5-4d63-96c2-2f82d6272846"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',kernel_initializer='he_normal',input_shape=input_shape))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',kernel_initializer='he_normal'))\n",
    "model.add(MaxPool2D((2, 2)))\n",
    "model.add(Dropout(0.20))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu',padding='same',kernel_initializer='he_normal'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu',padding='same',kernel_initializer='he_normal'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu',padding='same',kernel_initializer='he_normal'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.0001)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=15, # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8dd6be49-de4f-4e76-a6c6-5f2dc9d4f304",
    "_execution_state": "idle",
    "_uuid": "9197045f0084aa72f0bd8ece8fb03eca9ab08622",
    "id": "46129c2b-020b-4900-b45e-e577e4dce4ee",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "33d2485e-df3b-415b-bf2c-3cc1d1afddc1",
    "_execution_state": "idle",
    "_uuid": "fc13b3bb1a906117ae78cfd03639e165072f2e45",
    "id": "d569dd2f-92d7-4d15-b3b4-06565fefdb12"
   },
   "outputs": [],
   "source": [
    "datagen.fit(X_train)\n",
    "h = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n",
    "                              epochs = epochs, validation_data = (X_val,Y_val),\n",
    "                              verbose = 1, steps_per_epoch=X_train.shape[0] // batch_size\n",
    "                              , callbacks=[learning_rate_reduction],)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e0f319f7-c701-4ce4-b100-a0db07b9edef",
    "_uuid": "4410fb664affc57163466e4949390b9b97a5d291",
    "id": "ed0d678f-9351-4a31-98ce-335b7535d0b3"
   },
   "source": [
    "## Basic Simple Plot And Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "19003034-e42b-4ec4-99d6-abefc7411451",
    "_uuid": "0963a61adf30eba3b8c0d885eee69063e086634d",
    "id": "81b4a395-c581-4899-a6ac-eb3536858c48"
   },
   "outputs": [],
   "source": [
    "final_loss, final_acc = model.evaluate(X_val, Y_val, verbose=0)\n",
    "print(\"Final loss: {0:.6f}, final accuracy: {1:.6f}\".format(final_loss, final_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2c64c843-e1d0-449f-b5a5-e51955a30caf",
    "_uuid": "f5355803304624fae4bde1b4829d6329433395d6",
    "id": "a2ecbebc-1a67-4498-9a75-890938fe3d9c"
   },
   "outputs": [],
   "source": [
    "# Look at confusion matrix \n",
    "#Note, this code is taken straight from the SKLEARN website, an nice way of viewing confusion matrix.\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Predict the values from the validation dataset\n",
    "Y_pred = model.predict(X_val)\n",
    "# Convert predictions classes to one hot vectors \n",
    "Y_pred_classes = np.argmax(Y_pred, axis = 1) \n",
    "# Convert validation observations to one hot vectors\n",
    "Y_true = np.argmax(Y_val, axis = 1) \n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_mtx, classes = range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "04c6a010-c928-4acb-bfed-3426a474cf18",
    "_execution_state": "idle",
    "_uuid": "cfffb6b672be442d54317e6d92b2c0b180a91934",
    "id": "514aaf72-258f-4528-8ef5-22e2849236f5"
   },
   "outputs": [],
   "source": [
    "print(h.history.keys())\n",
    "accuracy = h.history['acc']\n",
    "val_accuracy = h.history['val_acc']\n",
    "loss = h.history['loss']\n",
    "val_loss = h.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "57d9d586-928d-4d6b-9ee7-21e2071e3631",
    "_uuid": "a4c3acd1a00f77cf809d7f7867545e03133ae36c",
    "id": "37a3f88e-3f89-4f19-87f0-c8d4a5cb989e"
   },
   "outputs": [],
   "source": [
    "# Errors are difference between predicted labels and true labels\n",
    "errors = (Y_pred_classes - Y_true != 0)\n",
    "\n",
    "Y_pred_classes_errors = Y_pred_classes[errors]\n",
    "Y_pred_errors = Y_pred[errors]\n",
    "Y_true_errors = Y_true[errors]\n",
    "X_val_errors = X_val[errors]\n",
    "\n",
    "def display_errors(errors_index,img_errors,pred_errors, obs_errors):\n",
    "    \"\"\" This function shows 6 images with their predicted and real labels\"\"\"\n",
    "    n = 0\n",
    "    nrows = 2\n",
    "    ncols = 3\n",
    "    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True)\n",
    "    for row in range(nrows):\n",
    "        for col in range(ncols):\n",
    "            error = errors_index[n]\n",
    "            ax[row,col].imshow((img_errors[error]).reshape((28,28)))\n",
    "            ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(pred_errors[error],obs_errors[error]))\n",
    "            n += 1\n",
    "\n",
    "# Probabilities of the wrong predicted numbers\n",
    "Y_pred_errors_prob = np.max(Y_pred_errors,axis = 1)\n",
    "\n",
    "# Predicted probabilities of the true values in the error set\n",
    "true_prob_errors = np.diagonal(np.take(Y_pred_errors, Y_true_errors, axis=1))\n",
    "\n",
    "# Difference between the probability of the predicted label and the true label\n",
    "delta_pred_true_errors = Y_pred_errors_prob - true_prob_errors\n",
    "\n",
    "# Sorted list of the delta prob errors\n",
    "sorted_dela_errors = np.argsort(delta_pred_true_errors)\n",
    "\n",
    "# Top 6 errors \n",
    "most_important_errors = sorted_dela_errors[-6:]\n",
    "\n",
    "# Show the top 6 errors\n",
    "display_errors(most_important_errors, X_val_errors, Y_pred_classes_errors, Y_true_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bcff5ccd-a9e2-4b1b-bd5a-1ba7342a5063",
    "_uuid": "bdbee7b242258cfed6bdb133690ef60b2460b6a1",
    "id": "84f6fd76-a85f-48df-bb2e-e7013d9db665"
   },
   "source": [
    "## Activations Look Like What?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "59000bb4-e5e5-4c69-8c32-6e4555297b2b",
    "_uuid": "e3140af1b8d24957702f3aa0ad36b269faa2c84d",
    "id": "83292c05-1795-4ece-a008-e0be48ebdd44"
   },
   "source": [
    "It looks like diversity of the similar patterns present on multiple classes effect the performance of the classifier although CNN is a robust architechture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f2f32aac-0426-456c-aacd-c009052027f0",
    "_uuid": "fc25e889e5783e51be1bf6cfa0a43189ee3f9d97",
    "id": "e145e44d-29d8-4faa-9b0d-91845c892be2"
   },
   "outputs": [],
   "source": [
    "test_im = X_train[154]\n",
    "plt.imshow(test_im.reshape(28,28), cmap='viridis', interpolation='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d3f60e88-da0c-4b99-bb3d-104bf36ea1c9",
    "_uuid": "2c1df53f0cd628623fc0db430b2a11bc5a915ef9",
    "id": "2628ccde-85f0-4e04-9c4d-7dd738dc00d0"
   },
   "source": [
    "**Let's see the activation of the 2nd channel of the first layer:**\n",
    "\n",
    "**Had taken help from the keras [docs](https://keras.io/getting-started/faq/#how-can-i-obtain-the-output-of-an-intermediate-layer), this [answer](https://stackoverflow.com/questions/41711190/keras-how-to-get-the-output-of-each-layer) on  StackOverFlow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "49d82f65-b772-4e52-addc-b0dad8c32831",
    "_uuid": "75c2f529fc00f9d7afd1a9ee82107339cf9a0316",
    "id": "64492348-2df7-40c9-9c5e-42cb59fcc94b"
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "layer_outputs = [layer.output for layer in model.layers[:8]]\n",
    "activation_model = models.Model(input=model.input, output=layer_outputs)\n",
    "activations = activation_model.predict(test_im.reshape(1,28,28,1))\n",
    "\n",
    "first_layer_activation = activations[0]\n",
    "plt.matshow(first_layer_activation[0, :, :, 4], cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "39aea2f5-efd4-4dc4-850d-677f16f27a61",
    "_uuid": "52223ddedf9c6d4e5d408a1535e7d2d718a171fc",
    "id": "6fdf5ad4-02b9-4d05-89cc-ebf1b0a77ee7"
   },
   "source": [
    "**Let's plot the activations of the other conv layers as well.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "80c2eda5-be86-4b86-ba18-55816fee55a9",
    "_uuid": "7dc5fe4bc164f504d9584ccab9efa70fac60e1ee",
    "id": "37506253-61ad-4239-b716-a4dec5825d90"
   },
   "outputs": [],
   "source": [
    "model.layers[:-1]# Droping The Last Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3eb0d4ec-fb0a-4b90-8c3e-9763957794d1",
    "_uuid": "d08dcd431e4103537a18a2eccc6956b57860618b",
    "id": "2f0b7432-f20d-47c1-a1fe-31293b186f23"
   },
   "outputs": [],
   "source": [
    "layer_names = []\n",
    "for layer in model.layers[:-1]:\n",
    "    layer_names.append(layer.name) \n",
    "images_per_row = 16\n",
    "for layer_name, layer_activation in zip(layer_names, activations):\n",
    "    if layer_name.startswith('conv'):\n",
    "        n_features = layer_activation.shape[-1]\n",
    "        size = layer_activation.shape[1]\n",
    "        n_cols = n_features // images_per_row\n",
    "        display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
    "        for col in range(n_cols):\n",
    "            for row in range(images_per_row):\n",
    "                channel_image = layer_activation[0,:, :, col * images_per_row + row]\n",
    "                channel_image -= channel_image.mean()\n",
    "                channel_image /= channel_image.std()\n",
    "                channel_image *= 64\n",
    "                channel_image += 128\n",
    "                channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
    "                display_grid[col * size : (col + 1) * size,\n",
    "                             row * size : (row + 1) * size] = channel_image\n",
    "        scale = 1. / size\n",
    "        plt.figure(figsize=(scale * display_grid.shape[1],\n",
    "                            scale * display_grid.shape[0]))\n",
    "        plt.title(layer_name)\n",
    "        plt.grid(False)\n",
    "        plt.imshow(display_grid, aspect='auto', cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "62162db6-d6b1-4639-8604-5c672065b2b4",
    "_uuid": "5a8b881e43f6cb5ddf242a03d2589388012cf10c",
    "id": "1caf0073-d049-445e-88ce-b6277ebdf075"
   },
   "outputs": [],
   "source": [
    "layer_names = []\n",
    "for layer in model.layers[:-1]:\n",
    "    layer_names.append(layer.name) \n",
    "images_per_row = 16\n",
    "for layer_name, layer_activation in zip(layer_names, activations):\n",
    "    if layer_name.startswith('max'):\n",
    "        n_features = layer_activation.shape[-1]\n",
    "        size = layer_activation.shape[1]\n",
    "        n_cols = n_features // images_per_row\n",
    "        display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
    "        for col in range(n_cols):\n",
    "            for row in range(images_per_row):\n",
    "                channel_image = layer_activation[0,:, :, col * images_per_row + row]\n",
    "                channel_image -= channel_image.mean()\n",
    "                channel_image /= channel_image.std()\n",
    "                channel_image *= 64\n",
    "                channel_image += 128\n",
    "                channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
    "                display_grid[col * size : (col + 1) * size,\n",
    "                             row * size : (row + 1) * size] = channel_image\n",
    "        scale = 1. / size\n",
    "        plt.figure(figsize=(scale * display_grid.shape[1],\n",
    "                            scale * display_grid.shape[0]))\n",
    "        plt.title(layer_name)\n",
    "        plt.grid(False)\n",
    "        plt.imshow(display_grid, aspect='auto', cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "eba54d2a-7078-44ec-a7ca-87b0fece7861",
    "_uuid": "c695cedecaaed016df2983fbf271177b7dc3a6e4",
    "id": "2be07913-be21-47f6-8321-9d1ca1cbe8f7"
   },
   "outputs": [],
   "source": [
    "layer_names = []\n",
    "for layer in model.layers[:-1]:\n",
    "    layer_names.append(layer.name) \n",
    "images_per_row = 16\n",
    "for layer_name, layer_activation in zip(layer_names, activations):\n",
    "    if layer_name.startswith('drop'):\n",
    "        n_features = layer_activation.shape[-1]\n",
    "        size = layer_activation.shape[1]\n",
    "        n_cols = n_features // images_per_row\n",
    "        display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
    "        for col in range(n_cols):\n",
    "            for row in range(images_per_row):\n",
    "                channel_image = layer_activation[0,:, :, col * images_per_row + row]\n",
    "                channel_image -= channel_image.mean()\n",
    "                channel_image /= channel_image.std()\n",
    "                channel_image *= 64\n",
    "                channel_image += 128\n",
    "                channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
    "                display_grid[col * size : (col + 1) * size,\n",
    "                             row * size : (row + 1) * size] = channel_image\n",
    "        scale = 1. / size\n",
    "        plt.figure(figsize=(scale * display_grid.shape[1],\n",
    "                            scale * display_grid.shape[0]))\n",
    "        plt.title(layer_name)\n",
    "        plt.grid(False)\n",
    "        plt.imshow(display_grid, aspect='auto', cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "755625bf-de66-45ac-96d2-4204d95e2ced",
    "_uuid": "52100b7260f819aeab482023ebc181990d96fcde",
    "id": "3b6d8e65-4aab-479c-98cc-90e11d554a5a"
   },
   "source": [
    "## Classifcation Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fdf357db-a224-4073-9f74-c3b0e748b858",
    "_uuid": "fade6e45a61151bed5bfebfa77fe6e52e44ee1b7",
    "id": "e8521d8b-5220-455a-ac33-c9f2e26124f2"
   },
   "outputs": [],
   "source": [
    "# Predict the values from the validation dataset\n",
    "Y_pred = model.predict(X_val)\n",
    "# Convert predictions classes to one hot vectors \n",
    "Y_pred_classes = np.argmax(Y_pred, axis = 1)\n",
    "Y_true_classes = np.argmax(Y_val, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e5e02af9-d6a5-4f0f-aa1c-08433e867ded"
   },
   "outputs": [],
   "source": [
    "Y_pred_classes[:5], Y_true_classes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f1e6858b-0fbb-476c-8e74-56c57c80057f",
    "_uuid": "49e840a9a0c94b05b6dfbb9bb761fee412ea7624",
    "id": "5a54eb72-3df7-4a14-9cb7-a2a079751c3e"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = [\"Class {}\".format(i) for i in range(num_classes)]\n",
    "print(classification_report(Y_true_classes, Y_pred_classes, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "004e5744c22242bd8a9e3083ea096c2a"
   },
   "outputs": [],
   "source": [
    "# model metadata\n",
    "model.to_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "17f54c658f0c4b5d8bd2bf40e4d9d23c"
   },
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "823a3a26b18941cd861067e31e3fbd9e"
   },
   "outputs": [],
   "source": [
    "from dsx_ml.ml import save\n",
    "\n",
    "model_name = 'Digits_Keras_Model'\n",
    "saved_model_output = save(name = model_name,\n",
    "                          model = model,\n",
    "                          x_test=test_run_df.drop('label', axis=1),\n",
    "                          y_test=test_run_df['label'],\n",
    "                          labelColumn_json = [{\"name\": \"label\", \"type\": \"int\"}],\n",
    "                          algorithm_type = 'Classification',\n",
    "                          source='digits_keras.ipynb',\n",
    "                          description='This is a sample model for a digits use case'\n",
    "                         )\n",
    "saved_model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8f68209a831b49fe8bc496a8fd78a423"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2604a6f7a92c4d4596f7a85e39ffdc1b"
   },
   "outputs": [],
   "source": [
    "with open(f\"/user-home/{os.environ['DSX_USER_ID']}/DSX_Projects/{os.environ['DSX_PROJECT_NAME']}/models/{model_name}/metadata.json\") as infile:\n",
    "    metadata_dict = json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8acb25c20922485585d25b29c71fe399"
   },
   "outputs": [],
   "source": [
    "print(f\"Model Type: {metadata_dict['algorithm']}\")\n",
    "print(\"Feature(s):\")\n",
    "for feature in metadata_dict['features']:\n",
    "    print('    '+feature['name'])\n",
    "\n",
    "print(f\"Latest Model Version: {metadata_dict['latestModelVersion']}\")\n",
    "print(\"Label(s):\")\n",
    "for label in metadata_dict['labelColumns']:\n",
    "    print('    '+label['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4c75b0dca3a7407687033e14e0900c0b"
   },
   "source": [
    "# Creating the Submission File (Optional only if submitting to Kaggle for test/ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7fe384c1-4777-4c9a-a11e-762c448b5265",
    "_execution_state": "idle",
    "_uuid": "4cadfded20b04c8dfd1929699330565d774285b9",
    "id": "d6482a0f-2641-4cf8-824a-a006617e5934"
   },
   "outputs": [],
   "source": [
    "predicted_classes = model.predict_classes(X_test)\n",
    "submissions=pd.DataFrame({\"ImageId\": list(range(1,len(predicted_classes)+1)),\n",
    "                         \"Label\": predicted_classes})\n",
    "submissions.head()\n",
    "# submissions.to_csv(\"asd.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5b1614c9dd2b40738e4a3daa58b047bf"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 with GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
